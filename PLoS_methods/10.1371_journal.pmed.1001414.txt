We systematically reviewed the literature to evaluate the current evidence on two common strategies: (a) supervised and (b) unsupervised self-testing strategies in high- and low-risk populations worldwide. A supervised strategy (self-testing and counselling processes) was always aided by a health care professional (HCP). An unsupervised strategy was performed by a self-tester without any help, but with counselling and linkage to care offered off-site (e.g., over the phone) by a HCP. Our specific objectives included documentation of all outcomes from implementation research associated with self-testing and counselling strategies (acceptability, accuracy, feasibility, cost, and counselling preferences). Further, data on challenges, concerns, and barriers documented from qualitative research or mixed methods studies were also synthesized. This review was reported following PRISMA guidelines. Search Strategy and Identification of Studies: For the period of January 1, 2000–October 30, 2012, we searched seven electronic databases (Medline [via PubMed], Biosis, PsycINFO, Cinahl, African Medicus, LILACS, and EMBASE) and abstracts from six major HIV/sexually transmitted infections (STIs) conferences (Canadian Association of HIV Research [CAHR], International Society for Sexually Transmitted Diseases Research [ISSTDR], International AIDS Society [IAS], Conference on Retroviruses and Opportunistic Infections [CROI], Infectious Diseases Society of America [IDSA], and the Inter Science Conference on Antimicrobial Agents and Chemotherapy [ICAAC]). Additionally, we reviewed bibliographies and contacted the authors for original data. We included abstracts if full-texts were not available. Our search string (limited to humans) was: (1) “HIV”[MeSH] OR “HIV Seropositivity”[MeSH] OR “HIV Infections”[MeSH] AND (2) (“Self Care”[MeSH]) OR “Self Administration”[MeSH]) OR “Point-of-Care Systems”[MeSH] OR “self*test*” OR “rapid*test*.” Two reviewers (JS and SS) independently screened all citations. Please refer to the flow chart for details (Figure 1).

Figure data removed from full text. Figure identifier and caption: 10.1371/journal.pmed.1001414.g001 Flow chart of study search and selection. Full-text articles, brief reports, or abstracts that evaluated HIV self-testing strategies in any part of the world were included. Reviews, perspectives, editorials, and studies that did not evaluate self-testing strategies (home-based non self test) were excluded (Figure 1).

Two reviewers independently abstracted data from quantitative (JS and SS) and qualitative (SP and JS) studies. Concordance between reviewers was high at 90%. Disagreements were resolved by consultation with a third reviewer (NPP). A pre-piloted data abstraction form was used. Variables such as study characteristics, populations, study design, type of strategy, and outcomes were tabulated (Tables 2–4).

Table data removed from full text. Table identifier and caption: 10.1371/journal.pmed.1001414.t002 Characteristics of included studies. aThe summary score for quality critique represents the number of criteria reported, over the total number of criteria.bSample size for “cost preference and willingness to pay (WTP) (USD)” and “feasibility linkages errors” (Table 3) outcomes was 519, as data were reported in combination with participants from another testing program.cAbstract.NA, not available/not applicable; STI, sexually transmitted infection.

Table data removed from full text. Table identifier and caption: 10.1371/journal.pmed.1001414.t003 Study outcomes: acceptability, accuracy, agreement and cost preference. FN, false negative; K, kappa statistic; NA, not available; NPV, negative predictive value; PPV, positive predictive value; WTP, willingness to pay.

Table data removed from full text. Table identifier and caption: 10.1371/journal.pmed.1001414.t004 Study outcomes: counselling preference, feasibility, linkages, errors, motivation, label comprehension, and test preference. NA, not available; WTP, willingness to pay.

Quality Assessment and Data Synthesis: A quality critique of quantitative data from cross-sectional (Tables S1 and S2) and cohort studies (Table S3) was performed using the STROBE reporting checklist [11]. Two articles, although not peer reviewed, were critiqued using the STROBE checklist as they were reporting outcomes of cohort and cross-sectional studies [12],[13]. Similarly, a conference abstract reporting a RCT (Table S4) was appraised using the CONSORT guidelines [14]. A guide [15] for critically appraising qualitative research was used to appraise qualitative studies [12],[16]–[19]. The only study that could not be quality critiqued was an announcement of an implementation strategy through a conference abstract [20]. Due to lack of standardized reporting of primary and secondary outcomes, a meta-analysis was not conducted.

