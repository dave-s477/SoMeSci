Accelerometer data from the Study of Early Child Care and Youth Development were analyzed to address the study objective. The original monitoring protocol was approved by each participating university's ethics committee (University of Arkansas; University of California; University of Kansas; University of New Hampshire/Wellesley; Pennsylvania State University/University of Pittsburgh; Temple University; University of Virginia; University of Washington; Western Carolina Center; and University of Wisconsin) and written consent was obtained from each participant. Details regarding the enrollment procedure and research protocol are available from the study's website (http://www.nichd.nih.gov/research/supported/seccyd/pages/overview.aspx). Accelerometer data were collected across a 7-day monitoring period using 1-minute epochs at mean ages of 9, 11, 12, and 15 yrs. ActiLife software (version 6.4.3) was used to detect and remove daily non-wear intervals between the hours of 7:00 and 22:00. Similar to other studies [3], non-wear periods included intervals of at least 60 consecutive minutes of zero activity counts, allowing for 2 minutes of counts between 0 and 100. Epochs exceeding 20,000 counts/min were reset to zero. Daily wear time was determined by removing daily non-wear periods. At each mean age, four separate data sets were created using minimum daily time requirements of 6, 8, 10, and 12 hrs. Accelerometer data were then interpreted in a manner consistent with the approach used in the International Children Accelerometer Database [10], where the amount of MVPA (mins/day) was determined using a threshold of 3000 counts/min. A total of 1082 youth were enrolled in the accelerometer protocol at 9 yrs. Age-related trends in activity have been previously reported with these data [13]; however, the objective of the current study was not addressed. Descriptive analyses were conducted for accelerometer wear time and MVPA by age and wear time criteria. Missing value analyses were conducted to report the proportion of missing data by day of the week and Little's chi-square statistic was used to report the mechanism of missingness. The null hypothesis for Little's chi-square test states that the data are MCAR; therefore, p-values <0.05 were considered significant and under this circumstance the missing data would be MAR or NMAR. Several reviews of MAR, MCAR, and NMAR exist [14], [15], but a brief interpretation is provided. Missing data are likely to be MAR [16], and under this mechanism the pattern of missingness is systematically related to some observed characteristic. In this situation, it is assumed that the actual variables where data are missing are not the cause of the incomplete data. MCAR is a sub-category of MAR [17], but comparatively more stringent, and assumes that missing data are unrelated to the variables being studied. In this context, individuals with missing data represent a simple random sample of the full sample (i.e., individuals with complete data are indistinguishable from those with incomplete data). Under the third mechanism (NMAR), the pattern of missing data is related to unobserved characteristic(s). Of the three missing data mechanisms, only MCAR can be empirically tested because MAR and NMAR are dependent upon unobserved data. Descriptive and missing value analyses were conducted using SPSS v20. To address the study's primary objective, reliability coefficients using complete (nd  =  7) and observable (1 ≤ nd ≤ 7) accelerometer data were compared using G theory methods. Although G theory has been described in the literature [18], [19], few studies have applied this approach to PA research [12], [20]–[24]. Following the framework outlined by Brennan [18], the current study employed a single facet (participant × day) design with missing data, where variance component estimates were derived using analogous T terms for the object of measurement (participants (ô2p)), the facet (day (ô2d)), and the interaction term which is confounded with unsystematic or unmeasured error (ô2 pd). Derived variance components were then used to calculate two types of error (absolute (ô2Δ) and relative (ô2δ)). Absolute, or criterion-referenced, error is the error involved in using a participant's mean score as an estimate of their universe score (i.e., ô2Δ  =  (ô2 d/d) + (ô2 pd/d)), whereby d is the harmonic mean of  (i.e., the number of days with acceptable data from each participant) [18] and is derived using Equation 1. (Equation) In contrast, relative error is associated with norm-referenced interpretations of measurement and equals the variance of the observed mean score for participants (S2 p) minus participant variance (ô2δ  =  S2 p – ô2 p) (Equation 2). (Equation) A complex issue arises in the calculation of S2 p because the mean score for each participant is based on a different number of acceptable days, ranging from 1 to 7. Variance components obtained from the unbalanced design were used in the D study to derive a reliability coefficient that characterized complete data (nd  =  7) (Ep2Complete  =  ô2 p/[ô2 p + (ô2 pd/nd)]) and, specific to this study, a separate coefficient that characterized all observable data (1≤ nd ≤ 7) (Ep2Observed  =  ô2 p/S2 p). Coefficients range from 0 to 1. In PA research, reliability coefficients ≥ 0.80 are desirable. Standard error of the mean (SEM), which provides an indication of the uncertainty associated with each measure, was calculated for each condition by taking the square root of the absolute error term. The SEM is expressed in the same metric unit of measurement and represents a 68% CI for the participant's universe score. Variance components, error estimates, and reliability coefficients were derived using EXCEL macros created by the corresponding author (see Tables S1 and S2 for a detailed description of the G theory calculations).

