Twenty-five individuals (11 women) participated for monetary compensation after online recruitment. Seventeen subject data were originally recollected for the control task of a previous work [15]. All the analyses presented here are new. All participants were right-handed Spanish speakers, aged from 20 to 37 years (M = 25.31, SEM = 0.71). All participants had normal or corrected-to-normal vision, no color-vision deficiency, no history of neurological diseases, and no current psychiatric diagnosis or psychotropic prescriptions. All participants provided their written informed consent to participate in this study and the Ethics Committee of the Pontificia Universidad Católica de Chile approved the experimental protocol. All experiments were performed at the Cognitive Neuroscience Laboratory of the Department of Psychiatry of the University. Participants played as proposers in a repeated version of the Ultimatum Game (see Figure 1). Subjects believed they were playing either with a human partner or a computer partner, but they were actually always playing with a computational simulation (see below). Participants began their participation by reading on-screen instructions describing the game. At the beginning of each game, participants watched the fixation cross (10 seconds, fixation phase). Then, a signal on the screen indicated whether the game was against a computer (“PC”) or a human (“H”) partner. Each game consisted of 15 rounds and each participant played as a proposer 32 times with different simulated responders (16 human games and 16 computer games, randomly distributed). For computer games, the experimenter explained to the participant that the computer simulation assigned a probability to accept the offer given the amount of money offered (a direct relation), and that this probability could change between different games but not during a game with the same computer partner. Importantly, the simulation used in human and computer games was the same. Each trial had three phases as follows: In the first (offer phase, variable duration), the proposer had to make the offer. In the second (anticipation phase, 1.5–4 seconds), the proposer waited for the response of the partner. In the last phase (feedback phase, 1 second), the response was revealed to the proposer. At the end of each game, the earnings each player had made in the game were revealed. After the set of games concluded, the experimenter interviewed each participant individually in order to check whether they had understood the game correctly. The amount of money each participant received depended on his/her performance in one of the 32 games chosen randomly, and ranged from 6,000 to 12,000 Chilean pesos, 12 to 24 USD approximately.

Simulations used in the tasks were based on a mixed logistic modeling of 33 people playing as receptors with other people (for more details see [13]). Using this model, we were able to create different virtual players. All participants played with the same simulated partners. Specifically, the simulation algorithm assigns a probability to reject or accept the offer given the following two equations: for round (x) = 1, and for round (x) >1,where  is the logit transform of the probability of rejection for the round x, Ox the offer, ΔOx the change of offer in relation to the preceding offer, and PRx the preceding response. The coefficients for each regressor were composed by a population parameter (by) and a random effect for each simulated responder (ryi, y = regressor and i = simulated partner). The simulation and experimental setting generated a credible human interaction for the following reasons: (1) The distributions of acceptances and rejections, and the offering behaviors related to a rejection in the simulation game were similar to those obtained in a real human game [13], suggesting that simulated responders elicited comparable behaviors in proposers. (2) During post hoc interviews, experimenters asked participants whether they believed that they had played against a human counterpart. All participants indicated that they actually believed that they had played against another human and that they felt the human games different from the computer games. We used the  to the quantification of the risk per each offer made.

Continuous EEG recordings were obtained with a 40-electrode NuAmps EEG System (Compumedics Neuroscan). All impedances were kept below 5 kΩ. Electrode impedance was retested during pauses to ensure stable values throughout the experiment. All electrodes were referenced to averaged mastoids during acquisition and the signal was digitized at 1 kHz. Electro-oculogram was obtained with four electrodes with both vertical and horizontal bipolar derivation. All recordings were acquired using Scan 4.3 (Compumedics Neuroscan) and stored for off-line treatment. At the end of each session, electrode position and head points were digitalized using a 3D tracking system (Polhemus Isotrak).

EEG signals were preprocessed using a 0.1–100 Hz band-pass Butterworth filter (third-order, forward and reverse filtering). Eye blinks were identified by a threshold criterion of ±100 µV, and their contribution was removed from each dataset using principal component analysis by singular value decomposition and spatial filter transform using Scan 4.3 (Compumedics Neuroscan). Other remaining artifacts (e.g., muscular artifacts) were detected by visual inspection of the signal and the trials that contained them were removed. After this procedure, we obtained 424±33 artifact-free trials across the subjects. Time frequency (TF) distributions were obtained by means of the wavelet transform, between –1.5 and 1.5s. We displayed the result only for –1 to 1 s over the segmented signals to avoid edged artifact. A signal x(t) was convolved with a complex Morlet’s wavelet function defined as . Wavelets were normalized and thus  the width of each wavelet function  was chosen to be 7; where . TF contents was represented as the energy of the convolved signal: . Thus, we obtained the phase and amplitude per each temporal bin (in steps of 10 ms) and frequency (from 4 to 30 Hz in step of 1 Hz). We used for analysis only the 90 riskiest and the 90 safest offers per subject and condition, in order to ensure equal number of trials for statistical comparison. For all power spectrum analysis, we used the dB of power related to a baseline during the fixation phase (ten seconds at the beginning of each game, Figure 1).

The neural current density time series at each elementary brain location was estimated by applying a weighted minimum norm estimate inverse solution [16] with unconstrained dipole orientations in single-trials. A tessellated cortical mesh template surface derived from the default anatomy of the Montreal Neurological Institute (MNI/Colin27) wrapped to the individual head shape (using ∼300 headpoints per subject) was used as a brain model to estimate the current source distribution. We defined 3×390 sources constrained to the segmented cortical surface (3 orthogonal sources at each spatial location, avoiding deep and basal structures since the sensitivity of the EEG signal to the activity of those structures is poor), and computed a three-layer (scalp, inner skull, outer skull) boundary element conductivity model and the physical forward model [17]. The measured electrode level data  is assumed to be linearly related to a set of cortical sources  and additive noise , where L is the physical forward model. The inverse solution was then derived as  where W is the inverse operator, R and C are the source and noise covariances respectively, the superscript T indicates the matrix transpose, and λ2 is the regularization parameter. R was the identity matrix that was modified to implement depth-weighing (weighing exponent: 0.8 [18]), The regularization parameter λ was set to 1/3. To estimate cortical activity at the cortical sources, the recorded raw EEG time series at the sensors x(t) were multiplied by the inverse operator W to yield the estimated source current, as a function of time, at the cortical surface: . Since this is a linear transformation, it does not modify the spectral content of the underlying sources. It is therefore possible to undertake time–frequency analysis on the source space directly. Finally, we reduced the number of sources by keeping a single source at each spatial location that pointed into the direction of maximal variance. To this end, we applied a principal component analysis to covariance matrix obtained from the 3 orthogonal time series estimated at each source location. This resulted in a single filter for each spatial location that was then applied to the complex valued data to derive frequency specific single trial source estimates. Since we used a small number of electrodes (40) and no individual anatomy for head model calculation, the spatial precision of the source estimations are limited. In order to minimize the possibility of erroneous results we only present source estimations if there are both statistically significant differences at the electrode level and the differences at the source levels survive a multiple comparison correction.

We consider the functional links in brain signals defined via the phase-locking value (PLV) computed between all pairs of electrodes or brain sources [19]. The PLV measures the inter-site-phase-clustering. To compute the PLVs, we used a complex Morlet’s wavelet function of 7 cycles. By means of this complex wavelet transform, an instantaneous phase  is obtained for each frequency component of signals i (electrodes or sources) at each trial (tr). The PLV between any pair of signals (i,k) is inversely related to the variability of phase differences across trials:where Ntr is the total number of trials. If the phase difference varies little across trials, its distribution is concentrated around a preferred value and PLV<1. In contrast, under the null hypothesis of a uniformity of phase distribution, PLV values are close to zero. Finally, to assess whether two different nodes are functionally connected, we calculated the significance probability of the PLVs by a Rayleigh test of uniformity of phase. According to this test, the significance of a PLV determined from Ntr can be calculated as  [20]. To correct for multiple testing, the False Discovery Rate (FDR, q<0.05) method was applied to each matrix of PLVs. In the construction of the networks, a functional connection between two brain sites was assumed as an undirected and weighted edge (functional connectivity strength between node wij = PLVij, for significant links and wij = 0 otherwise). We calculated the strength of inter-site-phase-clustering for each node (electrode or source) as the sum of all significant PLVs of that node.

To partition the functional networks in modules, we used a random walk-based algorithm [21]. This data-driven approach is based on the intuition that a random walker on a graph tends to remain into densely connected subsets corresponding to modules. To find the modular structure, the algorithm starts with a partition in which each node in the network is the sole member of a module. Modules are then merged by an agglomerative approach based on a hierarchical clustering method. At each step the algorithm evaluates the quality of partition , which compares the abundance of edges lying inside each community with respect to a null model. The modularity of a given partition is defined as,  where M is the number of modules, L is the total number of connections in the network,  is the number of connections between vertices in module s, and  is the sum of the degrees of the vertices in modules. The partition that maximizes  is considered as the partition that better captures the modular structure of the network. Further details can be found in [22], [23]. To evaluate the agreement between community structures we use the Rand index [24], which is a traditional criterion for comparison of different results provided by classifiers and clustering algorithms, including partitions with different numbers of classes or clusters. For two partitions P and P’, the Rand index is defined as ; where  is the number of pairs of data objects belonging to the same class in P and to the same class in P’,  is the number of pairs of data objects belonging to the same class in P and to different classes in P’,  is the number of pairs of data objects belonging to different classes in P and to the same class in P’, and  is number of pairs of data objects belonging to different classes in P and to different classes in P’. The Rand index has a straightforward interpretation as a percentage of agreement between the two partitions and it yields values between 0 (if the two partitions are randomly drawn) and 1 (for identical partition structures).

For pair comparison and correlation, we used non-parametric tests (Wilcoxon and Spearman correlation). For multiple regressions, we used robust linear regression. To correct for multiple comparisons in time-frequency chart and sources, we used the Cluster-based permutation test for the EEG data [25]. In the latter method, clusters of significant areas were defined by pooling neighboring sites (in the time-frequency chart) that showed the same effect (p<0.05). The cluster-level statistics was computed as the sum of the statistics of all sites within the corresponding cluster. We evaluated the cluster-level significance under the permutation distribution of the cluster that had the largest cluster-level statistics. The permutation distribution was obtained by randomly permuting the original data. After each permutation, the original statistical test was computed (e.g., Wilcoxon), and the cluster-level statistics of the largest cluster resulting was used for the permutation distribution. After 1,000 permutations, the cluster-level significance for each observed cluster was estimated as the proportion of elements of the permutation distribution greater than the cluster-level statistics of the corresponding cluster.

All behavioral statistical analyses were performed in R. The EEG signal processing was implemented in MATLAB using in-house scripts (LAN toolbox, available online at http://lantoolbox.wikispaces.com/, e.g. [26]). For the source estimation and head model, we used the BrainStorm [27] and openMEEG toolboxes [28].

